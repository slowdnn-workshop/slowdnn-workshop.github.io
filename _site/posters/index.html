<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>Accepted Papers | SLowDNN Workshop</title><meta name="generator" content="Jekyll v3.9.2" /><meta property="og:title" content="Accepted Papers" /><meta property="og:locale" content="en_US" /><meta name="description" content="A listing of the accepted works that will be presented as posters at the workshop" /><meta property="og:description" content="A listing of the accepted works that will be presented as posters at the workshop" /><link rel="canonical" href="http://localhost:4000/posters/" /><meta property="og:url" content="http://localhost:4000/posters/" /><meta property="og:site_name" content="SLowDNN Workshop" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Accepted Papers" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"A listing of the accepted works that will be presented as posters at the workshop","headline":"Accepted Papers","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo1.png"}},"url":"http://localhost:4000/posters/"}</script><body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"><title id="svg-external-link-title">(external link)</title><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-copy" viewBox="0 0 16 16"><title>Copy</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"><title>Copied</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"><path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg><div class="side-bar"><div class="site-header"> <a href="/" class="site-title lh-tight"><div class="site-logo"></div></a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a></div><nav aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a><li class="nav-list-item"><a href="/schedule/" class="nav-list-link">Schedule</a><li class="nav-list-item"><a href="/speakers/" class="nav-list-link">Speakers</a><li class="nav-list-item active"><a href="/posters/" class="nav-list-link active">Accepted Papers</a><li class="nav-list-item"><a href="/tutorials/" class="nav-list-link">Tutorials</a><li class="nav-list-item"><a href="/travel/" class="nav-list-link">Travel</a><li class="nav-list-item"><a href="/organizers/" class="nav-list-link">Organizers</a><li class="nav-list-item"><a href="/sponsors/" class="nav-list-link">Host Institution</a><li class="nav-list-item"><a href="/submission/" class="nav-list-link">Call for Papers</a><li class="nav-list-item"><a href="/past_workshops/" class="nav-list-link">Past workshops</a></ul></nav><footer class="site-footer"> For inquiries about the workshop, please contact <a href="mailto:slowdnn.workshop@gmail.com">slowdnn.workshop@gmail.com</a></footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="https://openreview.net/group?id=mbzuai.ac.ae/SLowDNN/2023/Workshop" class="site-button" > Submissions </a><li class="aux-nav-list-item"> <a href="https://docs.google.com/forms/d/e/1FAIpQLScMqcyVsrldFpZPwjajr2hcYz9aKx5V3riFNAEUQ7vswlrw7g/viewform" class="site-button" > Register </a></ul></nav></div><div id="main-content-wrap" class="main-content-wrap"><div id="main-content" class="main-content" role="main"><div class="splash"> <img src="/assets/images/splash0.jpg" alt="Splash photo of MBZUAI" /><div class="topleft"> Third Workshop on Seeking Low&#8209;Dimensionality in Deep&nbsp;Neural&nbsp;Networks</div><div class="bottomright"> January 2023,&nbsp;<a href="https://mbzuai.ac.ae/" target="_blank">MBZUAI</a></div></div><h1 id="poster-presentations"> <a href="#poster-presentations" class="anchor-heading" aria-labelledby="poster-presentations"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Poster Presentations</h1><p>Authors of accepted papers will present their work at one of three poster sessions at the workshop venue. A list of the accepted papers and the poster session assignments is given below, along with logistics information about the poster sessions.</p><h1 id="poster-session-logistics"> <a href="#poster-session-logistics" class="anchor-heading" aria-labelledby="poster-session-logistics"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Poster Session Logistics</h1><p>There are three evening poster sessions, on Wednesday, Thursday, and Friday â€“ see the <a href="/schedule">tentative schedule</a>. On the day of your poster session, you will be able to hang your poster up for the entire day. The poster sessions are held in a dedicated space at the workshop venue.</p><p>In addition, please note:</p><ul><li>The space available per poster is 40 inches wide by 50 inches high, so please ensure your poster will fit. (We recommend a 36 x 24 inch size.)<li>Your poster may be in any visual format you wish.<li>Please print and bring your poster with you as you travel. Unfortunately, MBZUAI does not have any official in-house facility for printing posters.</ul><h1 id="accepted-papers-and-tentative-poster-session-assignments"> <a href="#accepted-papers-and-tentative-poster-session-assignments" class="anchor-heading" aria-labelledby="accepted-papers-and-tentative-poster-session-assignments"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Accepted Papers and Tentative Poster Session Assignments</h1><h2 id="wednesday-january-4th"> <a href="#wednesday-january-4th" class="anchor-heading" aria-labelledby="wednesday-january-4th"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Wednesday, January 4th</h2><dl><dt>TT-NF: Tensor Train Neural Fields<dd>Anton Obukhov, Mikhail Usvyatsov, Christos Sakaridis, Konrad Schindler, Luc Van Gool<dt>Robust Calibration with Multi-domain Temperature Scaling<dd>Yaodong Yu, Stephen Bates, Yi Ma, Michael Jordan<dt>On the infinite-depth limit of finite-width neural networks<dd>Soufiane Hayou<dt>Combining Deep Learning and Adaptive Sparse Modeling for Low-dose CT Reconstruction<dd>Ling Chen, Zhishen Huang, Yong Long, Saiprasad Ravishankar<dt>Lottery Pools: Winning More by Interpolating Tickets without Increasing Training or Inference Cost<dd>Lu Yin, Shiwei Liu, Meng Fang, Tianjin Huang, Vlado Menkovski, Mykola Pechenizkiy<dt>Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!<dd>Shiwei Liu, Tianlong Chen, Zhenyu Zhang, Xuxi Chen, Tianjin Huang, AJAY KUMAR JAISWAL, Zhangyang Wang<dt>Deep Unfolded Tensor Robust PCA with Self-supervised Learning<dd>Harry Dong, Megna Shah, Sean Donegan, Yuejie Chi<dt>Closed-form Solutions of Learning Dynamics for Two-layer Nets for Collapsed Orthogonal Data<dd>Yutong Wang, Qing Qu, Wei Hu<dt>Closed-Loop Transcription via Convolutional Sparse Coding<dd>Xili Dai, Ke Chen, Shengbang Tong, Jingyuan Zhang, Xingjian Gao, Mingyang Li, Druv Pai, Yuexiang Zhai, Xiaojun Yuan, Heung-Yeung Shum, Lionel Ni, Yi Ma<dt>On the Ability of Graph Neural Networks to Model Interactions Between Vertices<dd>Noam Razin, Tom Verbin, Nadav Cohen<dt>On the Geometry of Reinforcement Learning in Continuous State and Action Spaces<dd>Saket Tiwari, Omer Gottesman, George Konidaris<dt>State-driven Implicit Modeling for Sparsity and Robustness in Neural Networks<dd>Alicia Y. Tsai, Juliette Decugis, Laurent El Ghaoui, Alper Atamturk<dt>Resource-Efficient Invariant Networks: Exponential Gains by Unrolled Optimization<dd>Sam Buchanan, Jingkai Yan, Ellie Haber, John Wright<dt>Robust Self-Guided Deep Image Prior<dd>Shijun Liang, Evan Bell, Saiprasad Ravishankar, Qing Qu<dt>Sparse-view Cone Beam CT Reconstruction using Data-consistent Supervised and Adversarial Learning from Scarce Training Data<dd>Gabriel Maliakal, Anish Lahiri, Marc Louis Klasky, Jeffrey A Fessler, Saiprasad Ravishankar<dt>Robustness of sparse local Lipschitz predictors<dd>Ramchandran Muthukumar, Jeremias Sulam<dt>Reverse Engineering $\ell_p$ attacks: A block-sparse optimization approach with recovery guarantees<dd>Darshan Thaker, Paris Giampouras, Rene Vidal</dl><h2 id="thursday-january-5th"> <a href="#thursday-january-5th" class="anchor-heading" aria-labelledby="thursday-january-5th"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Thursday, January 5th</h2><dl><dt>From Optimization Dynamics to Generalization Bounds via Lojasiewicz Gradient Inequality<dd>Fusheng Liu, Haizhao Yang, Soufiane Hayou, Qianxiao Li<dt>Unsupervised Manifold Linearizing and Clustering<dd>Tianjiao Ding, Shengbang Tong, Kwan Ho Ryan Chan, Xili Dai, Yi Ma, Benjamin David Haeffele<dt>Pursuit of a Discriminative Representation for Multiple Subspaces via Sequential Games<dd>Druv Pai, Michael Psenka, Chih-Yuan Chiu, Manxi Wu, Edgar Dobriban, Yi Ma<dt>VQ-Flows: Vector Quantized Local Normalizing Flows<dd>Chris Barton Dock, Sahil Sidheekh, Maneesh Kumar Singh, Radu Balan<dt>Latent-space disentanglement with untrained generator networks allows to isolate different motion types in video data<dd>Abdullah, Martin Holler, Malena Sabate Landman, Karl Kunisch<dt>Robust Training under Label Noise by Over-parameterization<dd>Sheng Liu, Zhihui Zhu, Qing Qu, Chong You<dt>Linear Convergence Analysis of Neural Collapse with Unconstrained Features<dd>Peng Wang, Huikang Liu, Can Yaras, Laura Balzano, Qing Qu<dt>Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?<dd>Kaiqi Zhang, Yu-Xiang Wang<dt>Sparse MoE with Random Routing as the New Dropout: Training Bigger and Self-Scalable Models<dd>Tianlong Chen, Zhenyu Zhang, AJAY KUMAR JAISWAL, Shiwei Liu, Zhangyang Wang<dt>Finding Better Descent Directions for Adversarial Training<dd>Fabian Latorre, Igor Krawczuk, Leello Tadesse Dadi, Thomas Pethick, Volkan Cevher<dt>APP: Anytime Progressive Pruning<dd>Diganta Misra, Bharat Runwal, Tianlong Chen, Zhangyang Wang, Irina Rish<dt>Effects of Data Geometry in Early Deep Learning<dd>Saket Tiwari, George Konidaris<dt>Dimension Mixer Model: Group Mixing of Input Dimensions for Efficient Function Approximation<dd>Suman Sapkota, Binod Bhattarai<dt>PSPS: Preconditioned Stochastic Polyak Step-size method for badly scaled data<dd>Farshed Abdukhakimov, XIANG CHULU, Dmitry Kamzolov, Robert M. Gower, Martin Takac</dl><h2 id="friday-january-6th"> <a href="#friday-january-6th" class="anchor-heading" aria-labelledby="friday-january-6th"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Friday, January 6th</h2><dl><dt>Neural Collapse with Normalized Features: A Geometric Analysis over the Riemannian Manifold<dd>Can Yaras, Peng Wang, Zhihui Zhu, Laura Balzano, Qing Qu<dt>Robustness via deep low rank representations<dd>Amartya Sanyal, Puneet K. Dokania, Varun Kanade, Philip Torr<dt>Intrinsic dimensionality and generalization properties of the $\mathcal{R}$-norm inductive bias<dd>Clayton Sanford, Navid Ardeshir, Daniel Hsu<dt>DynamicViT: Making Vision Transformer faster through layer skipping<dd>Amanuel Negash Mersha, Sammy Assefa<dt>SinkGAT: Doubly-Stochastic Graph Attention<dd>Tianlin Liu, Cheng Shi, Anastasis Kratsios, Ivan Dokmanic<dt>SMUG: Towards Robust MRI Reconstruction by Smoothed Unrolling<dd>Hui Li, Jinghan Jia, Shijun Liang, Yuguang Yao, Saiprasad Ravishankar, Sijia Liu<dt>Semi-private learning via low dimensional structures<dd>Yaxi Hu, Francesco Pinto, Amartya Sanyal, Fanny Yang<dt>Certified Defenses Against Near-Subspace Unrestricted Adversarial Attacks<dd>Ambar Pal, Rene Vidal<dt>Representation Learning Through Manifold Flattening and Reconstruction<dd>Michael Psenka, Druv Pai, Vishal G Raman, Shankar Sastry, Yi Ma<dt>Lifted Bregman Training of Neural Networks<dd>Xiaoyu Wang, Martin Benning<dt>Flat minima generalize for low-rank matrix recovery<dd>Lijun Ding, Dmitriy Drusvyatskiy, Maryam Fazel<dt>Are All Losses Created Equal: A Neural Collapse Perspective<dd>Jinxin Zhou, Chong You, Xiao Li, Kangning Liu, Sheng Liu, Qing Qu, Zhihui Zhu<dt>Fast Evaluation of Multilinear Operations in Convolutional Tensorial Neural Networks<dd>Tahseen Rabbani, Jiahao Su, Xiaoyu Liu, David Chan, Geoffrey Sangston, Furong Huang<dt>Dimensionality compression and expansion in Deep Neural Networks<dd>Stefano Recanatesi, Matthew Farrell, Madhu Advani, Timothy Moore, Guillaume Lajoie, Eric Todd SheaBrown<dt>A picture of the space of typical learnable tasks<dd>Rahul Ramesh, Jialin Mao, Itay Griniasty, Rubing Yang, Han Kheng Teoh, Mark Transtrum, James Sethna, Pratik Chaudhari<dt>Deep Reinforcement Learning based Unrolling Network for MRI Reconstruction<dd>Chong Wang, Rongkai Zhang, Gabriel Maliakal, Saiprasad Ravishankar, Bihan Wen<dt>Bilevel learning of $\ell_{1}$ regularizers with closed-form gradients (BLORC)<dd>Avrajit Ghosh, Saiprasad Ravishankar</dl></div></div></div>
