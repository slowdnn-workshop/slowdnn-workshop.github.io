---
name: René Vidal
role: Speaker
website: http://vision.jhu.edu/rvidal.html
affiliation: Johns Hopkins
photo: vidal.jpeg
talk: Principled Defenses and Reverse Engineering of Adversarial Attacks in a Union of Subspaces
abstract: Deep neural network-based classifiers have been shown to be vulnerable to imperceptible perturbations to their input, such as ℓp-bounded norm adversarial attacks. This has motivated the development of many defense methods, which are then broken by new attacks, and so on. Recent work has also focused on the problem of reverse engineering adversarial attacks, which requires both recovering the clean signal and determining the type of attack (ℓ1, ℓ2 or ℓ∞). However, existing methods either do not come with provable guarantees, or they can certify the accuracy of the classifier only for very small perturbations. In this work, we assume that the data lies approximately in a union of low-dimensional linear subspaces and exploit this low-dimensional structure to develop a theory of adversarial robustness for subspace-sparse classifiers. We first derive geometric conditions on the subspaces under which any attacked signal can be decomposed as the sum of a clean signal plus an attack. We then derive norm-independent certification regions, showing that we can provably defend against specific unrestricted adversarial attacks.
---
